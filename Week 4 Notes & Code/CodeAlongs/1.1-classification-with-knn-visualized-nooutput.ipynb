{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors classification walkthrough\n",
    "\n",
    "In this notebook we are going to look at how the kNN algorithm classifies malignant vs. benign tumor category in the Wisconsin breast cancer dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## kNN\n",
    "\n",
    "The pseudocode algorithm for kNN is as follows:\n",
    "\n",
    "```\n",
    "for unclassified_point in sample:\n",
    "    for known_point in known_class_points:\n",
    "        calculate distances (euclidean or other) between known_point and unclassified_point\n",
    "    for k in range of specified_neighbors_number:\n",
    "        find k_nearest_points in known_class_points to unclassified_point\n",
    "    assign class to unclassified_point using \"votes\" from k_nearest_points\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "[NOTE: in the case of ties, sklearn's `KNeighborsClassifier()` will just choose the first class using uniform weights! If this is unappealing to you you can change the weights keyword argument to 'distance'.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Import necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "plotter = imp.load_source('plotter', '/Users/kiefer/github-repos/DSI-SF-2/utils/plotting/knn_plotter.py')\n",
    "from plotter import KNNBoundaryPlotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Load in the dataset\n",
    "\n",
    "My path, for example, below: is provided.\n",
    "\n",
    "(The file as suffix '.data' but is actually formatted as a .csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcw = pd.read_csv('/Users/kiefer/github-repos/DSI-SF-2/datasets/breast_cance_wisconsin/wdbc.data', \n",
    "                  header=None, index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.2 Renaming the columns\n",
    "\n",
    "The attributes below will be the columns of the dataset.\n",
    "\n",
    "      Attribute                     \n",
    "   --------------------------------------------\n",
    "   1. Sample code number [subject ID]\n",
    "   2. Class\n",
    "   3. Cell nucleus mean radius\n",
    "   4. Cell nucleus SE radius\n",
    "   5. Cell nucleus worst radius\n",
    "   6. Texture mean\n",
    "   7. Texture SE\n",
    "   8. Texture worst\n",
    "   9. Perimeter mean\n",
    "   10. Perimeter SE\n",
    "   11. Perimeter worst\n",
    "   12. Area mean\n",
    "   13. Area SE\n",
    "   14. Area worst\n",
    "   15. Smoothness mean\n",
    "   16. Smoothness SE\n",
    "   17. Smoothness worst\n",
    "   18. Compactness mean\n",
    "   19. Compactness SE\n",
    "   20. Compactness worst\n",
    "   21. Concavity mean\n",
    "   22. Concavity SE\n",
    "   23. Concavity worst\n",
    "   24. Concave points mean\n",
    "   25. Concave points SE\n",
    "   26. Concave points worst\n",
    "   27. Symmetry mean\n",
    "   28. Symmetry SE\n",
    "   29. Symmetry worst\n",
    "   30. Fractal dimension mean\n",
    "   31. Fractal dimension SE\n",
    "   32. Fractal dimension worst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names are taken from the dataset info file. \n",
    "\n",
    "For more information check out the information file:\n",
    "\n",
    "`../assets/datasets/wdbc.names`\n",
    "\n",
    "You can open it with a text editor of your choice.\n",
    "\n",
    "Create an array with the column names and assign them as the header when loading the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_names = ['id','malignant',\n",
    "                'nucleus_mean','nucleus_se','nucleus_worst',\n",
    "                'texture_mean','texture_se','texture_worst',\n",
    "                'perimeter_mean','perimeter_se','perimeter_worst',\n",
    "                'area_mean','area_se','area_worst',\n",
    "                'smoothness_mean','smoothness_se','smoothness_worst',\n",
    "                'compactness_mean','compactness_se','compactness_worst',\n",
    "                'concavity_mean','concavity_se','concavity_worst',\n",
    "                'concave_pts_mean','concave_pts_se','concave_pts_worst',\n",
    "                'symmetry_mean','symmetry_se','symmetry_worst',\n",
    "                'fractal_dim_mean','fractal_dim_se','fractal_dim_worst']\n",
    "\n",
    "bcw.columns = column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.3 Check out the dataset information\n",
    "\n",
    "Print out the head and the datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcw.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4 Recode the class variable to be 0 vs. 1\n",
    "\n",
    "The \"malignant\" class target variable is coded as \"B\" for benign and \"M\" as malignant. \n",
    "\n",
    "We need to recode this to a binary integer for classification, with \"1\" as malign and \"0\" as benign (malign is assigned to 1 because our goal is to predict malign tumors with the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bcw['malignant'] = bcw['malignant'].map(lambda x: 0 if x == \"B\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print bcw.malignant.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Break up the data and look at correlations\n",
    "\n",
    "Split up the data into 3 datasets for the \"mean\", \"standard error\", and \"worst\" statistics on each predictor variable.\n",
    "\n",
    "NOTE: The difference between standard error and standard deviation is subtle:\n",
    "\n",
    "**Standard deviation:**\n",
    "An estimate of distance between sample observations and the sample mean.\n",
    "\n",
    "** Standard error:**\n",
    "An estimate of distance between the sample mean and the real population mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A function that subsets the data to the columns indicating the\n",
    "# mean, se, or wrong variable types\n",
    "def df_subsetter(df, suffix):\n",
    "    column_select = [x for x in bcw.columns if suffix in x]\n",
    "    bcw_subset = bcw[['id','malignant'] + column_select]\n",
    "    bcw_subset.columns = [x.replace(suffix, '') for x in bcw_subset.columns]\n",
    "    return bcw_subset\n",
    "\n",
    "bcw_mean = df_subsetter(bcw, '_mean')\n",
    "bcw_se = df_subsetter(bcw, '_se')\n",
    "bcw_worst = df_subsetter(bcw, '_worst')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.1 Examine correlation matrices for the 3 datasets\n",
    "\n",
    "Look at the correlations between variables for each of the subset datasets, excluding the id column.\n",
    "\n",
    "Use a seaborn heatmap to make this easier on the eye.\n",
    "\n",
    "1. The mean columns subset\n",
    "2. The standard error columns subset\n",
    "3. The \"worst value\" columns subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_corr = bcw_mean[[x for x in bcw_mean.columns if x not in 'id']].corr()\n",
    "\n",
    "# Set the default matplotlib figure size:\n",
    "plt.rcParams['figure.figsize']=(9,7)\n",
    "\n",
    "# Generate a mask for the upper triangle (taken from seaborn example gallery)\n",
    "mask = np.zeros_like(mean_corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Plot the heatmap with seaborn.\n",
    "# Assign the matplotlib axis the function returns. This will let us resize the labels.\n",
    "ax = sns.heatmap(mean_corr, mask=mask)\n",
    "\n",
    "# Resize the labels.\n",
    "ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=14)\n",
    "ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=14)\n",
    "\n",
    "# If you put plt.show() at the bottom, it prevents those useless printouts from matplotlib.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "se_corr = bcw_se[[x for x in bcw_se.columns if x not in 'id']].corr()\n",
    "\n",
    "# Set the default matplotlib figure size:\n",
    "plt.rcParams['figure.figsize']=(9,7)\n",
    "\n",
    "# Generate a mask for the upper triangle (taken from seaborn example gallery)\n",
    "mask = np.zeros_like(se_corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Plot the heatmap with seaborn.\n",
    "# Assign the matplotlib axis the function returns. This will let us resize the labels.\n",
    "ax = sns.heatmap(se_corr, mask=mask)\n",
    "\n",
    "# Resize the labels.\n",
    "ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=14)\n",
    "ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=14)\n",
    "\n",
    "# If you put plt.show() at the bottom, it prevents those useless printouts from matplotlib.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "worst_corr = bcw_worst[[x for x in bcw_worst.columns if x not in 'id']].corr()\n",
    "\n",
    "# Set the default matplotlib figure size:\n",
    "plt.rcParams['figure.figsize']=(9,7)\n",
    "\n",
    "# Generate a mask for the upper triangle (taken from seaborn example gallery)\n",
    "mask = np.zeros_like(worst_corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Plot the heatmap with seaborn.\n",
    "# Assign the matplotlib axis the function returns. This will let us resize the labels.\n",
    "ax = sns.heatmap(worst_corr, mask=mask)\n",
    "\n",
    "# Resize the labels.\n",
    "ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=14)\n",
    "ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=14)\n",
    "\n",
    "# If you put plt.show() at the bottom, it prevents those useless printouts from matplotlib.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.2 Look at correlations between mean, standard error, and worst within variable\n",
    "\n",
    "Look at the correlations between each single variables mean, se, and worst value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# A function that prints the variable name, subsets the data to just\n",
    "# be columns that have those variable names, and print out the\n",
    "# correlation between the variables\n",
    "def variable_corr_heatmapper(df, varname):\n",
    "    var_corr = df[[x for x in df.columns if varname in x]].corr()\n",
    "    \n",
    "    plt.rcParams['figure.figsize']=(6,4)\n",
    "    \n",
    "    mask = np.zeros_like(var_corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    \n",
    "    ax = sns.heatmap(var_corr, mask=mask)\n",
    "    \n",
    "    ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=14, rotation=30)\n",
    "    ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=14, rotation=0)\n",
    "    plt.show()\n",
    "    print '--------------------------------------------\\n'\n",
    "\n",
    "# get the variable names without the _mean, _se, _worst suffixes and\n",
    "# remove duplicate names by filtering\n",
    "varnames = [\n",
    "    x.replace('_mean','')\n",
    "    for x in bcw.columns\n",
    "    if x not in ['id','malignant']\n",
    "    and '_se' not in x\n",
    "    and '_worst' not in x\n",
    "]\n",
    "\n",
    "for var in varnames:\n",
    "    variable_corr_heatmapper(bcw, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Use seaborn's pairplot to visualize relationships between variables\n",
    "\n",
    "Look at the data using seaborn's `pairplot()` function. The hue will be the class variable \"malignant\". The variables will be the other columns excluding, of course, the subject ID column.\n",
    "\n",
    "Most of these predictors are highly correlated with the \"class\" variable. This is already an indication that our classifier is very likely to perform well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the seaborn style to have a white background\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "# This function does a pairplot across your variables with the color\n",
    "# set as the outcome \"malignant\" class variable\n",
    "def bcw_pairplotter(df, variables, sample_frac=0.3):\n",
    "    # sample_frac lets you specify an amount of the data to sample for the plot.\n",
    "    # this speeds up the function which can take awhile with the full data.\n",
    "    \n",
    "    # get the number of rows/data points:\n",
    "    rows = df.shape[0]\n",
    "    \n",
    "    # get downsample indicies for the data, if specified\n",
    "    if sample_frac < 1.0:\n",
    "        sample_inds = np.random.choice(range(0,rows), \n",
    "                                       size=int(round(rows*sample_frac)), \n",
    "                                       replace=False).astype(int)\n",
    "    \n",
    "    # make the pairplot for the variables:\n",
    "    pairs = sns.pairplot(df.iloc[sample_inds, :], \n",
    "                         vars=variables, \n",
    "                         hue=\"malignant\", \n",
    "                         palette=sns.xkcd_palette(['windows blue', 'amber']))\n",
    "\n",
    "\n",
    "# get out the column variable names to put into the pairplotter function\n",
    "colvars = [x for x in bcw_mean if x not in ['id','malignant']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.2 Plot the mean data subset with the pairplotter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcw_pairplotter(bcw_mean, colvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.3 Plot the standard error data subset with the pairplotter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcw_pairplotter(bcw_se, colvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.4 Plot the worst value data subset using the pairplotter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcw_pairplotter(bcw_worst, colvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. Test the performance of kNN classifiers on the data using cross-validation\n",
    "\n",
    "Let's see how the kNN classifier performs on the dataset with cross-validation.\n",
    "\n",
    "We are going to set some parameters in the classifier constructor. Some clarification below:\n",
    "\n",
    "1. **n_neighbors** specifies how many neighbors will vote on the class\n",
    "2. **weights** uniform weights indicate that all neighbors have the same weight\n",
    "3. **metric** and **p**: when distance is minkowski (the default) and p == 2 (the default), _this is equivalent to the euclidean distance metric_\n",
    "\n",
    "Load scikit's cross-validation module and import `StratifiedKFold`\n",
    "\n",
    "The `StratifiedKFold()` will return cross-validation _indices_ which you can use to subset your data in a for loop that runs the model and tests it. Get used to using indices for cross-validation on data â€“ it's easy to get soft with `cross_val_score`, but being able do it at a more \"manual\" level allows for a lot more power and customization. It also reinforces what is happening in your head during cross-validation, since you have to divide up the data yourself with the indices!\n",
    "\n",
    "The **stratified** version of cross-validation ensures that there are equal proportions the predicted class in each train-test fold. This is going to be a common practice in classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create X, y from the \"mean\" variables data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = bcw_mean['malignant'].values\n",
    "X = bcw_mean[colvars].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create cross-validation train/test indices:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_indices = StratifiedKFold(y, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to crossvalidate accuracy of a knn model acros folds\n",
    "def accuracy_crossvalidator(X, Y, knn, cv_indices):\n",
    "    \n",
    "    # list to store the scores/accuracy of folds\n",
    "    scores = []\n",
    "    \n",
    "    # iterate through the training and testing folds in cv_indices\n",
    "    for train_i, test_i in cv_indices:\n",
    "        \n",
    "        # get the current X train & test subsets of X\n",
    "        X_train = X[train_i, :]\n",
    "        X_test = X[test_i, :]\n",
    "\n",
    "        # get the Y train & test subsets of Y\n",
    "        Y_train = Y[train_i]\n",
    "        Y_test = Y[test_i]\n",
    "\n",
    "        # fit the knn model on the training data\n",
    "        knn.fit(X_train, Y_train)\n",
    "        \n",
    "        # get the accuracy predicting the testing data\n",
    "        acc = knn.score(X_test, Y_test)\n",
    "        scores.append(acc)\n",
    "        \n",
    "        print('Fold accuracy:', acc)\n",
    "        \n",
    "    print('Mean CV accuracy:', np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5.2: Cross-validate accuracy for a kNN model with 5 neighbors on the mean data subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_knn_n5 = KNeighborsClassifier(n_neighbors=5,\n",
    "                                   weights='uniform')\n",
    "\n",
    "accuracy_crossvalidator(X, y, mean_knn_n5, cv_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5.3: Cross-validate accuracy for a kNN model with 1 neighbor on the mean data subset\n",
    "\n",
    "As you can see the mean cross-validated accuracy is very high with 5 neighbors. \n",
    "\n",
    "Let's see what it's like when we use only 1 neighbor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_knn_n2 = KNeighborsClassifier(n_neighbors=1,\n",
    "                              weights='uniform')\n",
    "\n",
    "accuracy_crossvalidator(X, y, mean_knn_n2, cv_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5.4 Cross-validate accuracy for a kNN model with 5 neighbors on the standard error subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = bcw_se['malignant'].values\n",
    "X = bcw_se[colvars].values\n",
    "\n",
    "se_knn_n2 = KNeighborsClassifier(n_neighbors=5,\n",
    "                                 weights='uniform')\n",
    "\n",
    "accuracy_crossvalidator(X, y, se_knn_n2, cv_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5.5 Cross-validate accuracy for a kNN model with 5 neighbors on the worst value subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = bcw_worst['malignant'].values\n",
    "X = bcw_worst[colvars].values\n",
    "\n",
    "worst_knn_n5 = KNeighborsClassifier(n_neighbors=5,\n",
    "                                    weights='uniform')\n",
    "\n",
    "accuracy_crossvalidator(X, y, worst_knn_n5, cv_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6. Plot the kNN prediction boundary\n",
    "\n",
    "Even with 1 neighbor we do quite well at predicting the malignant observations.\n",
    "\n",
    "Below you can load an interactive KNN visualization class I wrote and put in your new `utils` directory.\n",
    "\n",
    "The `KNNBoundaryPlotter` class has 4 required arguments:\n",
    "\n",
    "    KNNBoundaryPlotter(data, predictor1, predictor2, class_target)\n",
    "    \n",
    "It will by default fit a visualization of the decision boundary across 1 to 100 nearest neighbors.\n",
    "\n",
    "The boundary is where the classifier will vote for malignant vs. benign classes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "plotter = imp.load_source('plotter', '/Users/kiefer/github-repos/DSI-SF-2/utils/plotting/knn_plotter.py')\n",
    "from plotter import KNNBoundaryPlotter\n",
    "\n",
    "kbp = KNNBoundaryPlotter(bcw_mean, 'area', 'symmetry', 'malignant', nn_range=range(1,101))\n",
    "\n",
    "kbp.knn_mesh_runner()\n",
    "\n",
    "kbp.knn_interact()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### 6.2 Try out some other variables of interest to you with the visualization class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7. What is the effect of increasing/decreasing the neighbors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 8 What could be wrong with using accuracy as your measure of performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 9. Explain changing the number of neighbors in terms of bias-variance tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
