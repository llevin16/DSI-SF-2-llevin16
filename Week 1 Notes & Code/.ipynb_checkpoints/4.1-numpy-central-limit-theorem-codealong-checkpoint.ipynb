{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Numpy and the Central Limit Theorem\n",
    "\n",
    "Week 1 | Lesson 4.1\n",
    "\n",
    "---\n",
    "\n",
    "In this lesson we'll be looking at numpy data structures and functions, and then exploring the Central Limit Theorem.\n",
    "\n",
    "---\n",
    "\n",
    "### Load useful packages\n",
    "\n",
    "We are loading a few packages here.\n",
    "\n",
    "`csv` and `seaborn` you are not too familiar with yet, if at all. `seaborn` is a plotting package that we will be using a lot througout this class. We will cover it in much more detail as time goes on. For now we are loading and aliasing it as `sns`.\n",
    "\n",
    "The `.csv` package does what we have been doing manually thus far. We will use `pandas` to do this later, but its another example of how to load csv data. Basic usage looks like:\n",
    "\n",
    "```python\n",
    "import csv\n",
    "with open('some.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        print row\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import csv\n",
    "import seaborn as sns\n",
    "\n",
    "# this line tells jupyter notebook to put the plots in the notebook rather than saving them to file.\n",
    "%matplotlib inline\n",
    "\n",
    "# this line makes plots prettier on mac retina screens. If you don't have one it shouldn't do anything.\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Load in the highest paid athletes dataset\n",
    "\n",
    "The path to this dataset is wherever you copied it over to. You'll see my path below. If you use an absolute path you'll have less trouble with the fact that it is relative to where you started the jupyter notebook in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rank',\n",
       " 'Name',\n",
       " 'Sport',\n",
       " 'Total Pay',\n",
       " 'Salary/Winnings',\n",
       " 'Endorsements',\n",
       " 'Nation',\n",
       " 'Gender',\n",
       " 'Year of birth',\n",
       " 'Birth Date',\n",
       " 'Place of Birth',\n",
       " 'Height (cm)',\n",
       " 'Wikipedia Page',\n",
       " 'dbpedia Page',\n",
       " 'Image',\n",
       " 'Description']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_athletes_csv = '/home/llevin/Desktop/DSI-SF-2/datasets/highest_paid_athletes/Athletes.csv'\n",
    "\n",
    "athletes = []\n",
    "import csv\n",
    "with open(path_to_athletes_csv, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        athletes.append(row)\n",
    "\n",
    "athletes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Put the data in a dictionary (rather than list) format\n",
    "\n",
    "We've again stored the data in a list of lists, where sublists are rows, and items of those sublists are column cells within rows.\n",
    "\n",
    "Another way to store data, which is more consistent with pandas, is in dictionary format, where the column headers are keys in a dictionary, and the columns themselves are the values associated with those keys.\n",
    "\n",
    "Convert the data to this dictionary format, keeping only the columns:\n",
    "\n",
    "```python\n",
    "['Rank','Name','Sport','Total Pay','Salary/Winnings','Endorsements','Nation','Gender','Year of birth', 'Height (cm)']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "athletes_dict = {}\n",
    "for lst in athletes[0]:\n",
    "    athletes_dict[lst] = []\n",
    "for index, lst in enumerate(athletes[0]):\n",
    "    for row in athletes[1:]:\n",
    "        athletes_dict[lst].append(row[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the numeric columns into float values. For the salary columns, you will need to remove the comma and dollar sign characters to properly convert to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in athletes_dict.keys():\n",
    "    try:\n",
    "        athletes_dict[column] = [float(string.replace(\"$\",\"\").replace(\",\",\"\")) for string in athletes_dict[column]]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Select numeric columns and convert to numpy arrays\n",
    "\n",
    "Pull out the three different salary columns and the height column into their own numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Plot the distributions of the numeric columns\n",
    "\n",
    "Use the distribution plotter function below to plot out the distributions for the four variables assigned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distribution_plotter(column, data):\n",
    "    sns.set(rc={\"figure.figsize\": (10, 7)})\n",
    "    sns.set_style('white')\n",
    "    dist = sns.distplot(data, hist_kws={'alpha':0.2}, kde_kws={'linewidth':5})\n",
    "    dist.set_title('Distribution of ' + column + '\\n', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. Basic linear algebra/matrix operations in numpy\n",
    "\n",
    "Overview of linear algebra/matrix operations in numpy.\n",
    "\n",
    "Numpy has an `np.matrix` and an `np.array`, what gives? Which should I use?\n",
    "\n",
    "Use `np.array`. This is the standard representation for matrices in numpy, and this is what we will use throughout the rest of the course. If you are interested you can read more about the differences online.\n",
    "\n",
    "#### 5.1 Indexing and slicing\n",
    "\n",
    "Subset the first 5 elements of total pay and height into new variables. Slicing (on 1D arrays) is the same as with python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Arithmetic operations\n",
    "\n",
    "Numpy allows easy \"vectorized\" arithmetic operations on arrays and matrices. Try:\n",
    "\n",
    "1. Dividing an array by a number with `/`\n",
    "2. Multiplying an array with `*`\n",
    "3. Adding and subtracting from an array with `+` and `-`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do these operations element-wise (as if using the `zip()` function) by using two arrays of the same length.\n",
    "\n",
    "Try dividing the 5-element total pay array by the 5-element height array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do the dot product of the arrays, which is for 1D-arrays the sum of the element-wise values multiplied together.\n",
    "\n",
    "Try it with `np.dot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Matrices vs. arrays \n",
    "\n",
    "You can make matrices by using `np.array()` on lists of lists (or numpy arrays). Combine the small height and pay arrays together into a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposition of a matrix is easy: just append a `.T` to the end of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create empty matrices of ones or zeros in numpy like so:\n",
    "\n",
    "```python\n",
    "# dimensions of the matrix (rows, cols, etc.):\n",
    "matrix_shape = (3,3)\n",
    "ones_mat = np.ones(matrix_shape)\n",
    "zeros_mat = np.zeros(matrix_shape)\n",
    "```\n",
    "\n",
    "Try it out with a matrix shape of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Slicing and indexing for matrices\n",
    "\n",
    "Numpy indexing and slicing of arrays/matrices greater than one dimension is easy once you get used to it. It is essentially the same as one dimensional selection or slicing, but you have an index or range for each dimension separated by commas in the brackets.\n",
    "\n",
    "For example, say I have matrix A:\n",
    "```python\n",
    "a = np.array([[1,2],[3,4],[5,6]])\n",
    "array([[1, 2],\n",
    "       [3, 4],\n",
    "       [5, 6]])\n",
    "```\n",
    "\n",
    "Get the first row:\n",
    "```python\n",
    "a[0,:]\n",
    "array([1, 2])\n",
    "```\n",
    "\n",
    "Get the second column:\n",
    "```python\n",
    "a[:,1]\n",
    "array([2, 4, 6])\n",
    "```\n",
    "\n",
    "Get the cell at row 3, column 1:\n",
    "```python\n",
    "a[2,0]\n",
    "5\n",
    "```\n",
    "\n",
    "Try it out yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 The concept of \"masking\"\n",
    "\n",
    "Selecting and operating on arrays can also be done through a process called **masking**, which we will be using very frequently on datasets.\n",
    "\n",
    "Numpy arrays can be indexed and subset with conditional statements in the brackets. These conditional statements are converted to True/False boolean arrays, which are used to select elements of an array (or not, aka \"mask\" the parts you don't want.)\n",
    "\n",
    "For example, all elements from `a` greater than 3:\n",
    "```python\n",
    "a[a>3]\n",
    "array([4, 5, 6])\n",
    "```\n",
    "\n",
    "or columns and rows from `a` where the first column of `a` is less than 5:\n",
    "```python\n",
    "a[a[:,0] < 5, :]\n",
    "array([[1, 2],\n",
    "       [3, 4]])\n",
    "```\n",
    "\n",
    "Make a matrix with the first column as players' heights, and the second column as their total pay. Subset using this masking logic to find all of the heights with a total pay above 10 million dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of heights with pay over 10,000,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 5.6 Review\n",
    "\n",
    "These are the essential kinds of operations we'll be using. The main takeaway is to get used to these kind of **vectorized** operations: doing arithmetic operations on every element of an array, either with single values or element-wise with another array.  **Masking** operations will become extremely important tools as we move into pandas data manipulation.\n",
    "\n",
    "We'll be doing this on data all the time using pandas. For example, adding a year to everyone's age, or multiplying the age column by the height column for each person (element-wise).\n",
    "\n",
    "For more detailed information on the capabilities of numpy operations, see:\n",
    "\n",
    "http://www.python-course.eu/matrix_arithmetic.php\n",
    "\n",
    "https://docs.scipy.org/doc/numpy-dev/user/numpy-for-matlab-users.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6. The Central Limit Theorem and the Law of Large Numbers\n",
    "\n",
    "The Central Limit Theorem (CLT) is one of the most important, if not **THE** most important theorems in statistics. While this lecture does not cover the implications so much as the theorem itself, know that this is the basis of Frequentist statistics.\n",
    "\n",
    "#### 6.1 The Law of Large Numbers\n",
    "\n",
    "But first... [The Law of Large Numbers (LLN)](https://en.wikipedia.org/wiki/Law_of_large_numbers)\n",
    "\n",
    "The LLN is (luckily) fairly straightforward, and a precursor to understanding the CLT. My simplified definition is:\n",
    "\n",
    "> Performing the same experiment a large number of times and taking the average of the results will result in a convergence to the true expected value of the experiment.\n",
    "\n",
    "Imagine, for example, you were to roll a die two times. In this case, the die is weighted, but you don't know how it is weighted. You get a 1 and a 5.\n",
    "\n",
    "From just these two experiments, our average is 3.0. If we were to stop here, we would assume that the expected value of the die is 3.0, and so slightly biased towards smaller numbers...\n",
    "\n",
    "#### 6.2 Numpy's `random` module and exploration of the LLN\n",
    "\n",
    "Before continuing, let's introduce a very important section of `numpy`: the `np.random` module.\n",
    "\n",
    "It is _very_ much worth reading over the documentation for the different functions available in `numpy.random`. Randomness is intrinsic to statistical theory, and, especially in a statistical course, we will be using it often.\n",
    "\n",
    "That's not to say you _won't_ be using it in practice. I guarantee that you will be consistently returning to these functions in your future jobs.\n",
    "\n",
    "For this example of the LLN, we will be using `np.random.choice()`, a function that samples from a provided array or list of elements. The arguments are:\n",
    "\n",
    "    a : the array from which to choose elements\n",
    "    size : the number of elements to draw\n",
    "    replace : whether to sample with replacement\n",
    "    p : a vector of probabilities equal to the number of elements in a which sums to one, specifying the probability of drawing the elements\n",
    "    \n",
    "Below are the _true_ probabilities of drawing each number on the die, or in other words the true weighting of the die:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "die = [1,2,3,4,5,6]\n",
    "\n",
    "weight = np.array([13.5, 1.2, 3.3, 2.2, 3.9, 12.8])\n",
    "weight = weight/np.sum(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain what each step in defining the `weight` vector means. What is the difference in describing the `weight` vector before and after dividing it by its sum to get the probabilities for `np.random.choice()`?\n",
    "\n",
    "Now we will \"roll the die\" different numbers of times. Use `np.random.choice` with the `die` and `weight` vector to assign different die roll \"experiments\":\n",
    "\n",
    "    1. 2 die roles\n",
    "    2. 5 die roles\n",
    "    3. 10 die rolls\n",
    "    4. 100 die rolls\n",
    "    5. 10000 die rolls\n",
    "    \n",
    "**Make sure to set replace=True !! Just because you rolled a 6, for example, doesn't mean you can't roll a 6 again.** This is the difference between rolling a die and say choosing items out of a bag without putting them back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Visualization of the LLN\n",
    "\n",
    "Below I have defined a histogram plotting function. Use the function to plot the histograms of each of the die roll experiments.\n",
    "\n",
    "You can look up the seaborn function `distplot` on the [seaborn API documentation](https://stanford.edu/~mwaskom/software/seaborn/api.html) to see how the histogram plot function works. Again, we'll be going into seaborn in depth very soon, but getting accustomed to reading documentation now is essential.\n",
    "\n",
    "**DON'T WORRY ABOUT UNDERSTANDING THE PLOTTING CODE AT THIS POINT!** Matplotlib is very confusing at first. We will spend a lot of time on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def histogram_plotter(title, data):\n",
    "    sns.set(rc={\"figure.figsize\": (10, 7)})\n",
    "    sns.set_style('white')\n",
    "    dist = sns.distplot(data, kde=False, bins=6)\n",
    "    \n",
    "    dist.axvline(np.mean(data), lw=5, c='darkred', ls='dashed')\n",
    "    average_roll = '{0:.2f}'.format(np.mean(data))\n",
    "    title = 'Distribution of ' + title + '; average = '  + average_roll + '\\n'\n",
    "    dist.set_title(title, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the **true expected value**. \n",
    "\n",
    "Hint: you can do this with the element-wise numpy array operations we covered earlier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected value is very close to the expected value of an evenly weighted die, but 1 and 6 are rolled much more often than the other numbers. This is an example of a **bi-modal** distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 6.4 On to the CLT\n",
    "\n",
    "So, how does the LLN relate to the CLT? Below is the high-level definition of [the CLT, (which is lifted from Wikipedia, of course)](https://en.wikipedia.org/wiki/Central_limit_theorem):\n",
    "\n",
    "> In probability theory, the central limit theorem (CLT) states that, given certain conditions, the arithmetic mean of a sufficiently large number of iterates of independent random variables, each with a well-defined (finite) expected value and finite variance, will be approximately normally distributed, regardless of the underlying distribution.\n",
    "\n",
    "**WTF does this mean?**\n",
    "\n",
    "It means that if you compute a mean of samples from ANY _true population distribution_, that mean will be normally distributed with \n",
    "\n",
    "**mean = mean of true population mean** and \n",
    "\n",
    "**standard deviation = standard error of the population mean**\n",
    "\n",
    "where a **standard error = (standard deviation) / sqrt(N)**\n",
    "\n",
    "check out:\n",
    "\n",
    "http://blog.vctr.me/posts/central-limit-theorem.html\n",
    "\n",
    "and http://www.usablestats.com/lessons/central_limit\n",
    "\n",
    "for a couple of gentle explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5 Exploring the CLT in code - back to the dice\n",
    "\n",
    "Let's say now we have two different conditions:\n",
    "\n",
    "1. Rolling the die 5 times _in batches_ 20 different times. Each time we roll the die 5 times, we take the mean of the batch and append it to a list.\n",
    "2. Rolling the die 5 times _in batches_ 300 different times. Each time we roll the die 5 times, we take the mean of the batch and append it to a list.\n",
    "3. Rolling the die 100 times _in batches_ 300 different times. Each time we roll the die 100 times, we take the mean of the batch and append it to a list.\n",
    "\n",
    "Code out these different scenarios. You should have 3 different lists with the means of the batch die-rolling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6 Plot the realization of the CLT\n",
    "\n",
    "Now, plot out these different mean distributions using the histogram plotting function.\n",
    "\n",
    "Also print out the standard deviation of the sample means as well as the standard deviation of the sample means **multipled by the square root of the sample means.** \n",
    "\n",
    "Multiplying by the square root of the sample means is necessary is a correction. What does this correction do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
